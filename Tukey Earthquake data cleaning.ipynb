{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4191dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22874742",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab32fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df = pd.read_csv('turkey_Data_1990_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d3039",
   "metadata": {},
   "source": [
    "### Important Note: This file was originally used to clean both japan and Turkey dataset, but later on I discovered that I had not properly downloaded the japan dataset from USGS. So the dataset for JAPAN is cleaned in another file which will be availble in the GITHUB and explained as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97d6dd",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e18585",
   "metadata": {},
   "source": [
    "## We will clean the data in both DataFrames. Our goals are the following:\n",
    "\n",
    "1). Choose which columns we need\n",
    "\n",
    "2). Remove all NA values\n",
    "\n",
    "3). Correct any Errors\n",
    "\n",
    "4). Make sure data is in accending orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8336bc7",
   "metadata": {},
   "source": [
    "### Removing columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82c75e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'latitude', 'longitude', 'depth', 'mag', 'magType', 'nst',\n",
       "       'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'place', 'type',\n",
       "       'horizontalError', 'depthError', 'magError', 'magNst', 'status',\n",
       "       'locationSource', 'magSource'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_df.columns\n",
    "#check for columns first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8be947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df = tur_df.drop(columns = ['nst', 'gap', 'dmin', 'rms', 'updated', 'net', 'horizontalError', 'depthError', 'magError', 'magNst', 'status', 'locationSource', 'magSource', 'type', 'id'])\n",
    "# Drop these columns as we don't need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edcb7e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'latitude', 'longitude', 'depth', 'mag', 'magType', 'place'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_df.columns\n",
    "# recheck columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876666a7",
   "metadata": {},
   "source": [
    "#### We need to remove NA values. We check for na values using .isna( ) in pandas. We checked every column and only na values were in the column 'Place' fpr both dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6380fb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15101</th>\n",
       "      <td>2008-03-12T18:53:31.000Z</td>\n",
       "      <td>40.6210</td>\n",
       "      <td>29.0110</td>\n",
       "      <td>11.200</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16474</th>\n",
       "      <td>2020-02-04T16:47:10.864Z</td>\n",
       "      <td>38.9976</td>\n",
       "      <td>27.9416</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16866</th>\n",
       "      <td>2023-01-18T10:42:39.023Z</td>\n",
       "      <td>38.4720</td>\n",
       "      <td>44.9169</td>\n",
       "      <td>16.660</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16912</th>\n",
       "      <td>2023-02-06T02:34:51.505Z</td>\n",
       "      <td>37.0822</td>\n",
       "      <td>37.0363</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16923</th>\n",
       "      <td>2023-02-06T03:16:16.646Z</td>\n",
       "      <td>38.0715</td>\n",
       "      <td>38.4951</td>\n",
       "      <td>17.340</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>2023-02-06T10:47:41.873Z</td>\n",
       "      <td>38.0443</td>\n",
       "      <td>36.6440</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17005</th>\n",
       "      <td>2023-02-06T11:51:22.063Z</td>\n",
       "      <td>38.0160</td>\n",
       "      <td>37.7225</td>\n",
       "      <td>16.818</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17038</th>\n",
       "      <td>2023-02-06T14:17:18.854Z</td>\n",
       "      <td>37.8732</td>\n",
       "      <td>37.3571</td>\n",
       "      <td>21.255</td>\n",
       "      <td>4.4</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>2023-02-06T18:03:53.807Z</td>\n",
       "      <td>37.9781</td>\n",
       "      <td>36.4456</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>mww</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17079</th>\n",
       "      <td>2023-02-06T19:49:40.242Z</td>\n",
       "      <td>38.0947</td>\n",
       "      <td>36.6422</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17085</th>\n",
       "      <td>2023-02-06T20:40:06.434Z</td>\n",
       "      <td>38.2636</td>\n",
       "      <td>37.9916</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17126</th>\n",
       "      <td>2023-02-07T07:26:36.313Z</td>\n",
       "      <td>38.0311</td>\n",
       "      <td>37.5813</td>\n",
       "      <td>16.180</td>\n",
       "      <td>4.4</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17154</th>\n",
       "      <td>2023-02-07T21:58:54.224Z</td>\n",
       "      <td>37.4201</td>\n",
       "      <td>36.9564</td>\n",
       "      <td>12.635</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17169</th>\n",
       "      <td>2023-02-08T09:13:07.114Z</td>\n",
       "      <td>36.6565</td>\n",
       "      <td>36.5077</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17200</th>\n",
       "      <td>2023-02-09T06:49:51.214Z</td>\n",
       "      <td>37.8752</td>\n",
       "      <td>37.6589</td>\n",
       "      <td>14.944</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17251</th>\n",
       "      <td>2023-02-12T12:25:22.576Z</td>\n",
       "      <td>36.7991</td>\n",
       "      <td>36.7677</td>\n",
       "      <td>4.270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17285</th>\n",
       "      <td>2023-02-17T19:10:38.916Z</td>\n",
       "      <td>38.0804</td>\n",
       "      <td>38.1774</td>\n",
       "      <td>15.797</td>\n",
       "      <td>3.9</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17286</th>\n",
       "      <td>2023-02-17T20:53:05.762Z</td>\n",
       "      <td>37.9028</td>\n",
       "      <td>32.5633</td>\n",
       "      <td>10.000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17321</th>\n",
       "      <td>2023-02-24T05:46:18.423Z</td>\n",
       "      <td>36.3086</td>\n",
       "      <td>36.0365</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>2023-02-25T12:41:13.746Z</td>\n",
       "      <td>38.0367</td>\n",
       "      <td>37.0670</td>\n",
       "      <td>6.703</td>\n",
       "      <td>4.4</td>\n",
       "      <td>mwr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17368</th>\n",
       "      <td>2023-03-12T12:31:22.559Z</td>\n",
       "      <td>37.9391</td>\n",
       "      <td>36.3290</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17429</th>\n",
       "      <td>2023-04-28T05:15:44.351Z</td>\n",
       "      <td>36.0905</td>\n",
       "      <td>36.0515</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time  latitude  longitude   depth  mag magType  \\\n",
       "15101  2008-03-12T18:53:31.000Z   40.6210    29.0110  11.200  4.3      mb   \n",
       "16474  2020-02-04T16:47:10.864Z   38.9976    27.9416  10.000  4.5      mb   \n",
       "16866  2023-01-18T10:42:39.023Z   38.4720    44.9169  16.660  4.3      mb   \n",
       "16912  2023-02-06T02:34:51.505Z   37.0822    37.0363  10.000  4.7      mb   \n",
       "16923  2023-02-06T03:16:16.646Z   38.0715    38.4951  17.340  4.3      mb   \n",
       "16987  2023-02-06T10:47:41.873Z   38.0443    36.6440  10.000  4.7      mb   \n",
       "17005  2023-02-06T11:51:22.063Z   38.0160    37.7225  16.818  4.5      mb   \n",
       "17038  2023-02-06T14:17:18.854Z   37.8732    37.3571  21.255  4.4      mb   \n",
       "17068  2023-02-06T18:03:53.807Z   37.9781    36.4456  10.000  5.2     mww   \n",
       "17079  2023-02-06T19:49:40.242Z   38.0947    36.6422  10.000  4.2     mwr   \n",
       "17085  2023-02-06T20:40:06.434Z   38.2636    37.9916  10.000  4.9      mb   \n",
       "17126  2023-02-07T07:26:36.313Z   38.0311    37.5813  16.180  4.4      mb   \n",
       "17154  2023-02-07T21:58:54.224Z   37.4201    36.9564  12.635  4.1      mb   \n",
       "17169  2023-02-08T09:13:07.114Z   36.6565    36.5077  10.000  4.3      mb   \n",
       "17200  2023-02-09T06:49:51.214Z   37.8752    37.6589  14.944  4.1      mb   \n",
       "17251  2023-02-12T12:25:22.576Z   36.7991    36.7677   4.270  4.2      mb   \n",
       "17285  2023-02-17T19:10:38.916Z   38.0804    38.1774  15.797  3.9     mwr   \n",
       "17286  2023-02-17T20:53:05.762Z   37.9028    32.5633  10.000  2.6      ml   \n",
       "17321  2023-02-24T05:46:18.423Z   36.3086    36.0365  10.000  4.0      mb   \n",
       "17329  2023-02-25T12:41:13.746Z   38.0367    37.0670   6.703  4.4     mwr   \n",
       "17368  2023-03-12T12:31:22.559Z   37.9391    36.3290  10.000  4.3      mb   \n",
       "17429  2023-04-28T05:15:44.351Z   36.0905    36.0515  10.000  4.1      mb   \n",
       "\n",
       "      place  \n",
       "15101   NaN  \n",
       "16474   NaN  \n",
       "16866   NaN  \n",
       "16912   NaN  \n",
       "16923   NaN  \n",
       "16987   NaN  \n",
       "17005   NaN  \n",
       "17038   NaN  \n",
       "17068   NaN  \n",
       "17079   NaN  \n",
       "17085   NaN  \n",
       "17126   NaN  \n",
       "17154   NaN  \n",
       "17169   NaN  \n",
       "17200   NaN  \n",
       "17251   NaN  \n",
       "17285   NaN  \n",
       "17286   NaN  \n",
       "17321   NaN  \n",
       "17329   NaN  \n",
       "17368   NaN  \n",
       "17429   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_tur = tur_df['place'].isna()\n",
    "tur_df[missing_tur]\n",
    "\n",
    "# This code allows us to first create a new  variable from the dataset to determine the null values which can then be showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2013b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df = tur_df.dropna(subset = ['place'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e3474",
   "metadata": {},
   "source": [
    "#### The next step of the process is to filter out any other locations that might be in our data which are not part of Japan or Turkey. \n",
    "\n",
    "#### When we took the data, we used a map and drew a rectangle to cover our area, and it is possible that bordering countries were included in the rectangle. We will now filter those countries out so we get a better and accurate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13dcf191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows for Turkey before filtering out other Countries/Regions\n",
      "time         17413\n",
      "latitude     17413\n",
      "longitude    17413\n",
      "depth        17413\n",
      "mag          17413\n",
      "magType      17413\n",
      "place        17413\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('No of rows for Turkey before filtering out other Countries/Regions')\n",
    "print(tur_df.count())\n",
    "\n",
    "# FIrst lets check the number of rows we initially have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1d8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df = tur_df[tur_df['place'].str.contains('Turkey')]\n",
    "\n",
    "# This will update our table \n",
    "# and we will only see rows which contain Turkey and japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158a8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows for Turkey After filtering out other Countries/Regions\n",
      "time         15503\n",
      "latitude     15503\n",
      "longitude    15503\n",
      "depth        15503\n",
      "mag          15503\n",
      "magType      15503\n",
      "place        15503\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('No of rows for Turkey After filtering out other Countries/Regions')\n",
    "print(tur_df.count())\n",
    "\n",
    "# no of rows after we filter out other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dc20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d4d9a06",
   "metadata": {},
   "source": [
    "#### Next we will convert the ISO8601 time to a better time format so it is easier to use for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fb912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_time = pd.to_datetime(tur_df['time'])\n",
    "\n",
    "# we will use datetime library to convert the iso time to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25d0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df['New Time'] = tur_time.dt.strftime('%H:%M:%S')\n",
    "\n",
    "# We have used strftime to break  and format the time from the ISO format \n",
    "# into hours, minutes and seconds\n",
    "\n",
    "tur_df['New Date'] = tur_time.dt.strftime('%d-%m-%y')\n",
    "\n",
    "# and used it to format our date as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8605930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also broke the date into seperate day, month, and year column so we can perform more analysis\n",
    "\n",
    "tur_df['day'] = tur_time.dt.day\n",
    "tur_df['month'] = tur_time.dt.month\n",
    "tur_df['year'] = tur_time.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f7e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jap_df = jap_df.drop(columns = 'place')\n",
    "tur_df = tur_df.drop(columns = 'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97e0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>New Time</th>\n",
       "      <th>New Date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1990-01-10T07:50:43.870Z</td>\n",
       "      <td>39.2790</td>\n",
       "      <td>28.2970</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>md</td>\n",
       "      <td>07:50:43</td>\n",
       "      <td>10-01-90</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1990-01-10T10:04:15.190Z</td>\n",
       "      <td>39.2800</td>\n",
       "      <td>28.2180</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>md</td>\n",
       "      <td>10:04:15</td>\n",
       "      <td>10-01-90</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1990-01-26T16:12:39.470Z</td>\n",
       "      <td>39.0160</td>\n",
       "      <td>26.9550</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.4</td>\n",
       "      <td>md</td>\n",
       "      <td>16:12:39</td>\n",
       "      <td>26-01-90</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1990-01-26T20:49:53.860Z</td>\n",
       "      <td>40.2890</td>\n",
       "      <td>27.3440</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>md</td>\n",
       "      <td>20:49:53</td>\n",
       "      <td>26-01-90</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1990-02-01T07:10:27.870Z</td>\n",
       "      <td>38.1790</td>\n",
       "      <td>26.5870</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.3</td>\n",
       "      <td>md</td>\n",
       "      <td>07:10:27</td>\n",
       "      <td>01-02-90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17430</th>\n",
       "      <td>2023-04-29T01:55:48.600Z</td>\n",
       "      <td>38.0984</td>\n",
       "      <td>36.4408</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>mb</td>\n",
       "      <td>01:55:48</td>\n",
       "      <td>29-04-23</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>2023-04-30T13:01:28.430Z</td>\n",
       "      <td>38.3404</td>\n",
       "      <td>37.6774</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>13:01:28</td>\n",
       "      <td>30-04-23</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>2023-05-01T21:36:01.751Z</td>\n",
       "      <td>38.1554</td>\n",
       "      <td>38.5956</td>\n",
       "      <td>17.018</td>\n",
       "      <td>4.1</td>\n",
       "      <td>mb</td>\n",
       "      <td>21:36:01</td>\n",
       "      <td>01-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>2023-05-03T06:20:54.763Z</td>\n",
       "      <td>37.5590</td>\n",
       "      <td>35.5859</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>mb</td>\n",
       "      <td>06:20:54</td>\n",
       "      <td>03-05-23</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17434</th>\n",
       "      <td>2023-05-03T17:16:38.636Z</td>\n",
       "      <td>38.0816</td>\n",
       "      <td>36.5226</td>\n",
       "      <td>10.473</td>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>17:16:38</td>\n",
       "      <td>03-05-23</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15503 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time  latitude  longitude   depth  mag magType  \\\n",
       "8      1990-01-10T07:50:43.870Z   39.2790    28.2970  10.000  3.7      md   \n",
       "10     1990-01-10T10:04:15.190Z   39.2800    28.2180  10.000  3.7      md   \n",
       "76     1990-01-26T16:12:39.470Z   39.0160    26.9550  10.000  3.4      md   \n",
       "77     1990-01-26T20:49:53.860Z   40.2890    27.3440  10.000  3.2      md   \n",
       "83     1990-02-01T07:10:27.870Z   38.1790    26.5870  10.000  3.3      md   \n",
       "...                         ...       ...        ...     ...  ...     ...   \n",
       "17430  2023-04-29T01:55:48.600Z   38.0984    36.4408  10.000  4.5      mb   \n",
       "17431  2023-04-30T13:01:28.430Z   38.3404    37.6774  10.000  4.1      mb   \n",
       "17432  2023-05-01T21:36:01.751Z   38.1554    38.5956  17.018  4.1      mb   \n",
       "17433  2023-05-03T06:20:54.763Z   37.5590    35.5859  10.000  4.4      mb   \n",
       "17434  2023-05-03T17:16:38.636Z   38.0816    36.5226  10.473  4.9      mb   \n",
       "\n",
       "       New Time  New Date  day  month  year  \n",
       "8      07:50:43  10-01-90   10      1  1990  \n",
       "10     10:04:15  10-01-90   10      1  1990  \n",
       "76     16:12:39  26-01-90   26      1  1990  \n",
       "77     20:49:53  26-01-90   26      1  1990  \n",
       "83     07:10:27  01-02-90    1      2  1990  \n",
       "...         ...       ...  ...    ...   ...  \n",
       "17430  01:55:48  29-04-23   29      4  2023  \n",
       "17431  13:01:28  30-04-23   30      4  2023  \n",
       "17432  21:36:01  01-05-23    1      5  2023  \n",
       "17433  06:20:54  03-05-23    3      5  2023  \n",
       "17434  17:16:38  03-05-23    3      5  2023  \n",
       "\n",
       "[15503 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82679e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02f4286",
   "metadata": {},
   "source": [
    "### Now we have completed the Data cleaning for both our Japan and Turkey datasets. We have not removed the original Time column as we still have to convert it to a timestamp for our Machine learning process. We will use rest of the vallues for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed9d771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_df.to_csv('tur_data_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808bafc",
   "metadata": {},
   "source": [
    "#### The final step is to save both dataframes into csv files which then we can access at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3faa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70187a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebcda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ed9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e7763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72690ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
